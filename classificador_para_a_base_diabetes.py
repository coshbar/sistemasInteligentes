# -*- coding: utf-8 -*-
"""Classificador_para_a_base_Diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14PGO_0sD1BAAkLJBV_uyXN_HxkDKYw03

**Link para os dados:** https://archive.ics.uci.edu/ml/datasets/Diabetes
"""

#CLASSIFICADORES
#Primeira parte será obter modelo classificador com a base Fertility
#1. Balanceamento dos dados
#2. Obter o modelo (treinar)
#3. Avaliar a acurácia do modelo

#1, Importar bibliotecas
import matplotlib.pyplot as plt
import pandas as pd
from imblearn.over_sampling import SMOTE
from collections import Counter
from pickle import dump
from pickle import  load
from sklearn.model_selection import  train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import  plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_validate

#Carregar aruqivo
ds = pd.read_csv('/content/diabetes.csv', sep = ',')
ds

# Avaliar se as classes estão balanceadas
print('# Frequencia das classes (atributo class)')
print(ds['class'].value_counts())

#Balancear os dados
#Segmentar os dados em atributos e classes
ds.classes = ds['class'] #Somente a coluna output
ds.atributos = ds.drop(columns = ['class']) #Todas as colunas exceto Output

#Construiu um objeto a partir do SMOTE e executar o método fit_resample
resampler = SMOTE() # Constroi o balanceador
#Executar o balanceamento
ds.atributos_b, ds.classes_b = resampler.fit_resample(ds.atributos, ds.classes)

#Verficiar a frequencia das classes balanceadas
print('# Frequencia das classes (atributo class) após balanceamento')
class_count = Counter(ds.classes_b)
class_count

#Integrar os dados em um objeto Data Frame
#Converter os atributos que estão como ndArray em DataFrame
ds.atributos_b = pd.DataFrame(ds.atributos_b)
ds.atributos_b.colums = []
ds.classes_b = pd.DataFrame(ds.classes_b)

#resolver os rótulos das colunas
    #todos os rótulos das colunas, exceto a última
ds.columns[:-1]
    #último rótulo da lista de rótulos do objeto dados
ds.columns[-1]  
    #atribui os rótulos (exceto do último) para o novo data frame
ds.atributos_b.columns = ds.columns[:-1]
    #atribui o último rótulo para o novo data frame
ds.classes_b.columns = [ds.columns[-1]] 

#Juntar os data frames
ds_b = ds.atributos_b.join(ds.classes_b, how = 'left')
ds_b

#treinar o modelo
#Segmentar a base de entrada em dois objetos. Um com os atributos e outro com as classes

#Segmentar os dados em parte para treinamento e parte para testes (Hold Out {70/30})
Atr_train, Atr_test, Class_train, Class_test = train_test_split(ds.atributos_b, ds.classes_b, test_size = 0.3)

#Treinar o modelo: Árvore de Decisão

#(Indutor) Construir um objeto a partir do DecisionTreeClassifier
tree = DecisionTreeClassifier()
#Treinar o modelo de ML
diabetes_tree = tree.fit(Atr_train, Class_train)

#2.6 Pretestar o modelo
Class_predict = diabetes_tree.predict(Atr_test)
Class_predict
# Imprimir as classes reservadas para test lado a lado com as classes pervistas no prete
print('classe teste x classe prevista')
i = 0
for i in range(0, len(Class_test)):
  print(Class_test.iloc[i][0], ' - ', Class_predict[i])

#Acurácia global do modelo
print('Acurácia Global (provisória):', metrics.accuracy_score(Class_test, Class_predict))

#matriz
plot_confusion_matrix(diabetes_tree, Atr_test, Class_test)
plt.show()

#Retorna os rótulos das classes dentro do modelo
print(confusion_matrix(Class_test, Class_predict, labels=diabetes_tree.classes_))

#cross validation
#(Indutor) Construir um objeto a partir do DecisionTreeClassifier
tree = DecisionTreeClassifier()
#Treinar o modelo de ML
diabetes_tree_cross = tree.fit(ds.atributos_b, ds.classes_b)

#Testar o modelo CROSS VALIDATION
scoring=['precision_macro','recall_macro']
#Rodar o cross validate da forma nativa
scores_cross = cross_validate(tree, ds.atributos_b, ds.classes_b, cv=10, scoring = scoring)

print('Matriz de sensibilidades:', scores_cross['test_precision_macro'])
print('Matriz de especificidades:', scores_cross['test_recall_macro'])
#Métricas finas: calcular as medias

#tn/tn+fp
print('Especificidade:', scores_cross['test_precision_macro'].mean())
#tp/tp+fn
print('Sensibilidade :', scores_cross['test_recall_macro'].mean())

#salvar modelo
#Árvore treinada com split e testada com Holdout
dump(diabetes_tree, open('diabetes_tree_model.pkl', 'wb'))

#Árvore treinada com full data e testada com cros validation
dump(diabetes_tree_cross, open('diabetes_tree_cross_model.pkl', 'wb'))

###### inferir classe
#Nova instância
novo_paciente = [[6, 148, 72, 35, 0, 33.6, 0.627, 50]]

#Abrir o modelo
diabetes_model = load(open('/content/diabetes_tree_model.pkl', 'rb'))
diabetes_cross_model = load(open('/content/diabetes_tree_cross_model.pkl', 'rb'))
print('Diabetes:', diabetes_model.predict_proba(novo_paciente))
print('Diabetes cross', diabetes_cross_model.predict_proba(novo_paciente))

novo_paciente = [[1,85,66,29,0,26.6,0.351,31]]

#Abrir o modelo
diabetes_model = load(open('/content/diabetes_tree_model.pkl', 'rb'))
diabetes_cross_model = load(open('/content/diabetes_tree_cross_model.pkl', 'rb'))
print('Diabetes:', diabetes_model.predict_proba(novo_paciente))
print('Diabetes cross', diabetes_cross_model.predict_proba(novo_paciente))