# -*- coding: utf-8 -*-
"""modelos_classificadores.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sgO-kUTWvFsBU8cAmx06bN9xgp7f84Iq

Link para dataset **https://archive.ics.uci.edu/ml/datasets/bank+marketing**

**PARTE 1**

1. Normalizar a base

2. Balancear os dados

3. Treinar um modelo classificador utilizando DecisionTree, RandomForest e SVM (Support Vector Machine)

4. Avaliar a acurácia dos modelos treinados utilizando Cross Validation

5. Selecionar e salvar o melhor modelo

**PARTE 2**

6. Desenvolver um módulo de inferência

  6.1 Receber os dados de uma nova instância

  6.2 Classificar a nova instância com o modelo salvo

  6.3 Demonstrar a distribuição probabilística da classificação realizada
"""

#Importar bibliotecas
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
import math
from imblearn.over_sampling import SMOTE
from collections import Counter
from pickle import dump
from pickle import load
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_validate
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import plot_confusion_matrix
from sklearn import svm
from sklearn import metrics
from sklearn import preprocessing
from scipy.spatial.distance import cdist

#Carregar arquivo
ds = pd.read_csv('/content/bank-full.csv', sep = ';')
ds

#search for unique values
for col in ds.columns:
    print(col + ' unique values are:\n{}'.format(sorted(ds[col].unique())))
    print('Total number of values in this column is: \t{}'.format(ds[col].nunique()))
    print(85 * '-')

pd.crosstab(ds["job"], ds["y"]).plot(kind = "bar", figsize=(20, 10), color = ["black", "lightgray"])

plt.title("Relacao entre job e Y", fontsize = 20)
plt.xlabel("Different reasons categories", fontsize = 18)
plt.ylabel("Frequency", fontsize = 12)
plt.legend(["Job", "Y"], fontsize = 15);

#cleaning the dataset changing data types
ds['job'] = pd.Categorical(ds['job']).codes
ds['marital'] = pd.Categorical(ds['marital']).codes
ds['education'] = pd.Categorical(ds['education']).codes
ds['default'] = pd.Categorical(ds['default']).codes
ds['housing'] = pd.Categorical(ds['housing']).codes
ds['loan'] = pd.Categorical(ds['loan']).codes
ds['contact'] = pd.Categorical(ds['contact']).codes
ds['month'] = pd.Categorical(ds['month']).codes
ds['poutcome'] = pd.Categorical(ds['poutcome']).codes
ds['y'] = pd.Categorical(ds['y']).codes

ds

# Avaliar se as classes estão balanceadas
print('# Frequencia das y (atributoy)')
print(ds['y'].value_counts())

#normalize the data
normalizer = preprocessing.MinMaxScaler()
normalizer_model = normalizer.fit(ds)

dump(normalizer_model, open("Normalizermodel_Bank.pkl", "wb"))

normalized_data = normalizer_model.fit_transform(ds)
normalized_data = pd.DataFrame(normalized_data, columns = ds.columns)
ds = normalized_data
print(ds)

#Balancear os dados
#Segmentar os dados em atributos e classes
ds.classes = ds['y'] #Somente a coluna output
ds.atributos = ds.drop(columns = ['y']) #Todas as colunas exceto Output

#Construiu um objeto a partir do SMOTE e executar o método fit_resample
#Constroi o balanceador
resampler = SMOTE()
#Executar o balanceamento
ds.atributos_b, ds.classes_b = resampler.fit_resample(ds.atributos, ds.classes)

#Verficiar a frequencia das classes balanceadas
print('# Frequencia das classes (atributo y) após balanceamento')
class_count = Counter(ds.classes_b)
class_count

#Integrar os dados em um objeto Data Frame
#Converter os atributos que estão como ndArray em DataFrame
ds.atributos_b = pd.DataFrame(ds.atributos_b)
ds.atributos_b.colums = []
ds.classes_b = pd.DataFrame(ds.classes_b)

#resolver os rótulos das colunas
    #todos os rótulos das colunas, exceto a última
ds.columns[:-1]
    #último rótulo da lista de rótulos do objeto dados
ds.columns[-1]  
    #atribui os rótulos (exceto do último) para o novo data frame
ds.atributos_b.columns = ds.columns[:-1]
    #atribui o último rótulo para o novo data frame
ds.classes_b.columns = [ds.columns[-1]] 

#Juntar os data frames
ds_b = ds.atributos_b.join(ds.classes_b, how = 'left')
ds_b

#treinar o modelo
#Segmentar a base de entrada em dois objetos. Um com os atributos e outro com as classes

#Segmentar os dados em parte para treinamento e parte para testes (Hold Out {70/30})
Atr_train, Atr_test, Class_train, Class_test = train_test_split(ds.atributos_b, ds.classes_b, test_size = 0.3)

#Treinar o modelo: Árvore de Decisão

#(Indutor) Construir um objeto a partir do DecisionTreeClassifier
tree = DecisionTreeClassifier()
#Treinar o modelo de ML
banks_tree = tree.fit(Atr_train, Class_train)

#Pretestar o modelo
Class_predict = banks_tree.predict(Atr_test)
Class_predict

#Acurácia global do modelo
print('Acurácia Global:', metrics.accuracy_score(Class_test, Class_predict))

#matriz
plot_confusion_matrix(banks_tree, Atr_test, Class_test)
plt.show()

#cross validation
#(Indutor) Construir um objeto a partir do DecisionTreeClassifier
tree = DecisionTreeClassifier()
#Treinar o modelo de ML
banks_tree_cross = tree.fit(ds.atributos_b, ds.classes_b)

#Testar o modelo CROSS VALIDATION
scoring = ['precision_macro','recall_macro']
#Rodar o cross validate da forma nativa
scores_cross = cross_validate(tree, ds.atributos_b, ds.classes_b, cv = 10, scoring = scoring)

print('Matriz de sensibilidades:', scores_cross['test_precision_macro'])
print('Matriz de especificidades:', scores_cross['test_recall_macro'])
#Métricas finas: calcular as medias

#tn/tn+fp
print('Especificidade:', scores_cross['test_precision_macro'].mean())
#tp/tp+fn
print('Sensibilidade :', scores_cross['test_recall_macro'].mean())

#salvar modelo
#Árvore treinada com split e testada com Holdout
dump(banks_tree, open('banks_tree_model.pkl', 'wb'))

#Árvore treinada com full data e testada com cros validation
dump(banks_tree_cross, open('banks_tree_cross_model.pkl', 'wb'))

#Treinar o modelo: RandomForest
#(Indutor) Construir um objeto a partir do DecisionTreeClassifier
forest = RandomForestClassifier()
#Treinar o modelo de ML
banks_forest = forest.fit(Atr_train, Class_train)

#Pretestar o modelo
Class_predict = banks_forest.predict(Atr_test)
Class_predict

#Acurácia global do modelo
print('Acurácia Global:', metrics.accuracy_score(Class_test, Class_predict))

#matriz
plot_confusion_matrix(banks_forest, Atr_test, Class_test)
plt.show()

#cross validation
#(Indutor) Construir um objeto a partir do RandomForestClassifier
forest = RandomForestClassifier()
#Treinar o modelo de ML
banks_forest_cross = forest.fit(ds.atributos_b, ds.classes_b)

#Testar o modelo CROSS VALIDATION
scoring = ['precision_macro', 'recall_macro']
#Rodar o cross validate da forma nativa
scores_cross = cross_validate(forest, ds.atributos_b, ds.classes_b, cv = 10, scoring = scoring)

print('Matriz de sensibilidades:', scores_cross['test_precision_macro'])
print('Matriz de especificidades:', scores_cross['test_recall_macro'])
#Métricas finas: calcular as medias

#tn/tn+fp
print('Especificidade:', scores_cross['test_precision_macro'].mean())
#tp/tp+fn
print('Sensibilidade :', scores_cross['test_recall_macro'].mean())

#salvar modelo
#Floresta treinada com split e testada com Holdout
dump(banks_forest, open('banks_forest_model.pkl', 'wb'))

#Floresta treinada com full data e testada com cros validation
dump(banks_forest_cross, open('banks_forest_cross_model.pkl', 'wb'))

#Treinar o modelo: #SVM 
#(Indutor) Construir um objeto a partir do SVM
svmmodel = svm.SVC(kernel='linear')
#Treinar o modelo de ML
banks_svm = svmmodel.fit(Atr_train, Class_train)

#Pretestar o modelo
Class_predict = banks_svm.predict(Atr_test)
Class_predict

#Acurácia global do modelo
print('Acurácia Global:', metrics.accuracy_score(Class_test, Class_predict))

#matriz
plot_confusion_matrix(banks_svm, Atr_test, Class_test)
plt.show()

#cross validation
#(Indutor) Construir um objeto a partir do SVC(kernel='linear')
svmmodel = svm.SVC(kernel='linear')
#Treinar o modelo de ML
banks_svm_cross = svmmodel.fit(ds.atributos_b, ds.classes_b)

#Testar o modelo CROSS VALIDATION
scoring = ['precision_macro', 'recall_macro']
#Rodar o cross validate da forma nativa
scores_cross = cross_validate(svmmodel, ds.atributos_b, ds.classes_b, cv = 10, scoring = scoring)

print('Matriz de sensibilidades:', scores_cross['test_precision_macro'])
print('Matriz de especificidades:', scores_cross['test_recall_macro'])
#Métricas finas: calcular as medias

#tn/tn+fp
print('Especificidade:', scores_cross['test_precision_macro'].mean())
#tp/tp+fn
print('Sensibilidade :', scores_cross['test_recall_macro'].mean())

#salvar modelo
#Svm treinado com split e testada com Holdout
dump(banks_svm, open('banks_svm_model.pkl', 'wb'))

#Sm treinado com full data e testada com cros validation
dump(banks_svm_cross, open('banks_svm_cross_model.pkl', 'wb'))

#inferir classe
#Nova instância
novo = [[58, 4, 1 ,2 ,0 ,2143 ,1 ,0 ,2 ,5 ,8 ,261 ,1 ,-1 ,0 ,3]]

#Abrir o modelo arvore
banks_model = load(open('/content/banks_tree_model.pkl', 'rb'))
banks_cross_model = load(open('/content/banks_tree_cross_model.pkl', 'rb'))
print('y:', banks_model.predict_proba(novo))
print('y cross', banks_cross_model.predict_proba(novo))

#Abrir o modelo forest
banks_model = load(open('/content/banks_forest_model.pkl', 'rb'))
banks_cross_model = load(open('/content/banks_forest_cross_model.pkl', 'rb'))
print('y:', banks_model.predict_proba(novo))
print('y cross', banks_cross_model.predict_proba(novo))

#Abrir o modelo svm
banks_model = load(open('/content/banks_svm_model.pkl', 'rb'))
banks_cross_model = load(open('/content/banks_svm_cross_model.pkl', 'rb'))
print('y:', banks_model.predict_proba(novo))
print('y cross', banks_cross_model.predict_proba(novo))