# -*- coding: utf-8 -*-
"""absenteeism_at_work_CLUSTERS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12hloC3PbwgnFFLi4gHLU_Y6Oe_hEPuFu

Utilizando a base de dados **Absenteeism at Work**, desenvolva um sistema inteligente, utilizando clusters para responder aos seguintes questionamentos:

* Quais são as causas de absenteísmo no trabalho conforme essa base de dados?
* Dados novos funcionários e os relatos sobre suas condições pessoais e as    demais informações que a base de dados suporta/entrega, o sistema deve      determinar se essa pessoa tem indicativo de absenteísmo.

**Link para os dados:** https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work

**Aspectos a serem considerados na implementação:**
* Deve-se realizar todos os tratamentos necessários sobre os dados;
* Utilizar KMeans e Expectation Maximization, obtendo dois modelos de cluster;
* Ao verificar se uma nova instância tem indicativo de absenteísmo, utilize os dois modelos é uma estratégia denominada hard fail, na qual, se um dos modelos indicar risco de falta (absenteísmo) essa será a inferência do sistema;
* Seu sistema deve possuir um módulo de indução e um módulo de inferência;
* Você deverá entregar a sua solução acompanhada de orientações simplificadas para o uso.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from scipy.spatial.distance import cdist
from pickle import dump
from pickle import load

# %matplotlib inline

#open csv
dataset = pd.read_csv('/content/Absenteeism_at_work.csv', sep = ';')

#search for unique values
for col in dataset.columns:
    print(col + ' unique values are:\n{}'.format(sorted(dataset[col].unique())))
    print('Total number of values in this column is: \t{}'.format(dataset[col].nunique()))
    print(85 * '-')

#plot graphic for Reason and Month of Absence
dataset["Reason for absence"].value_counts().plot(kind="bar", figsize=(20, 10), color = ['black'])

plt.title("Frequency of Reason for absence", fontsize = 20)
plt.xlabel("Reasons categories")
plt.ylabel("Absence frequency");

"""Top 5 of the reasons for being absent were:

1.   23 - Medical consultation
2.   28 - Dental consultation
3.   27 - Physiotherapy
4.   13 - Diseases of the musculoskeletal system and connective tissue
5.   0 - There is no explaination for this











"""

#discard all values where Reason for Absence is 0
dataset = dataset[dataset['Reason for absence'] != 0]

#add new column for prediction since most of the absenteeism time is less than 8 hours
dataset["Absenteeism time over 8 hours"] = dataset["Absenteeism time in hours"] >= 8
dataset["Absenteeism time over 8 hours"].value_counts()

dataset["Absenteeism time over 8 hours"].value_counts().plot(kind = "bar", figsize = (20, 10), color = ["black"]);
plt.title("Over Eight Hours of absenteeism", fontsize = 20)
plt.xlabel("True = More than 8 hours    False = Less than 8 hours", fontsize = 18)
plt.ylabel("Frequencies", fontsize = 12);

#cleaning the dataset changing data types
dataset['Reason for absence'] = dataset['Reason for absence'].astype('category')
dataset['Month of absence'] = dataset['Month of absence'].astype('category')
dataset['Day of the week'] = dataset['Day of the week'].astype('category')
dataset['Seasons'] = dataset['Seasons'].astype('category')
dataset['Disciplinary failure'] = dataset['Social drinker'].astype('bool')
dataset['Education'] = dataset['Education'].astype('category')
dataset['Social drinker'] = dataset['Social drinker'].astype('bool')
dataset['Social smoker'] = dataset['Social smoker'].astype('bool')

pd.crosstab(dataset["Reason for absence"], dataset["Absenteeism time over 8 hours"]).plot(kind = "bar", figsize=(20, 10), color = ["black", "lightgray"])

plt.title("Which Reasons caused more than 8 hours of absenteeism", fontsize = 20)
plt.xlabel("Different reasons categories", fontsize = 18)
plt.ylabel("Frequency", fontsize = 12)
plt.legend(["Less than 8 hours", "More than 8 hours"], fontsize = 15);

#as Absenteeism time in hours and ID columns can't help the analysis, we'll drop them
dataset.drop("Absenteeism time in hours", axis = 1, inplace= True)
dataset.drop("ID", axis = 1, inplace= True)
dataset.reset_index(drop = True, inplace= True)

dataset

#normalize the data
normalizer = preprocessing.MinMaxScaler()
normalizer_model = normalizer.fit(dataset)

dump(normalizer_model, open("Normalizermodel_Absenteeism.pkl", "wb"))

normalized_data = normalizer_model.fit_transform(dataset)
normalized_data

K = range(2, 101)

#distortion
distortion = []
for k in K:
    kmeansmodel = KMeans(n_clusters = k, random_state = 4).fit(normalized_data)
    distortion.append(
        sum(
            np.min(
                cdist(normalized_data, kmeansmodel.cluster_centers_, 'euclidean'), axis = 1
                ) / normalized_data.shape[0]
        )
    )

fix, ax = plt.subplots()

ax.plot(K, distortion)
ax.set(xlabel='N Clusters', ylabel='Distortion', title='Distortion Method')
ax.grid()
plt.show()

#inertia
inertia = []
for k in K:
    kmeansmodel = KMeans(n_clusters = k, random_state = 4).fit(normalized_data)
    inertia.append(kmeansmodel.inertia_)

fix, ax = plt.subplots()

ax.plot(K, inertia)
ax.set(xlabel='N Clusters', ylabel='Inertia', title='Inertia Method')
ax.grid()
plt.show()

#determinate ideal number of clusters
def optimal_cluster_number(metrics):
    #determinate the coordinates of the first point of the curve 
    x1 = 2
    y1 = metrics[0]

    #determinate the coordinates of the last point of the curve 
    x2 = len(metrics)
    y2 = metrics[-1]

    #stores the length of the perpendiculars 
    distances = []
    
    for i in range(len(metrics)):
        x0 = i + 2
        y0 = metrics[i]

        numerator = abs(((y2 - y1) * x0) - ((x2 - x1) * y0) + (x2 * y1) - (y2 * x1))
        denominator = math.sqrt((y2 - y1)**2 + (x2 - x1)**2)
    
        distances.append(numerator / denominator)

    return distances.index(max(distances)) + 2

nk_distortion = optimal_cluster_number(distortion)
nk_inertia = optimal_cluster_number(inertia)

print("Distortion method : " + str(nk_distortion))
print("Inertia method: " + str(nk_inertia))

#save the cluster model
#Kmeans cluster
Kmeansmodel = KMeans(n_clusters = nk_inertia, random_state = 4).fit(normalized_data)

dump(Kmeansmodel, open('Kmeansmodel_Absenteeism.pkl', 'wb'))

#save the cluster model
#Expectation maximization
Emmodel = GaussianMixture(n_components = nk_inertia, random_state = 4).fit(normalized_data)

dump(Emmodel, open('Emmodel_Absenteeism.pkl', 'wb'))

def predict_kmeans(input):
    return Absenteeism_Kmeansmodel.cluster_centers_[Absenteeism_Kmeansmodel.predict(input)]

def predict_em(input):
    return np.empty(shape = (Absenteeism_Emmodel.n_components, dataset.shape[1]))[Absenteeism_Emmodel.predict(input)]

input = [
        #01 - "Reason for absence" category[1 - 28]
        2,
        #02 - "Month of absence" category[1 - 12]	
        1, 
        #03 - "Day of the week" category[2 - 6]	
        4, 
        #04 - "Season" category[1 - 4]	
        4, 
        #05 - "Transportation expense"
        250,  
        #06 - "Distance from Residence to Work"
        120, 
        #07 - "Service time
        16, 
        #08 - "Age
        45, 
        #09 - "Work load Average/day
        239.554, 
        #10 - "Hit target
        97, 
        #12 - "Disciplinary failure
        0, 
        #13 - "Education 
        1, 
        #14 - "Son 
        2, 
        #15 - "Social drinker" bool[yes - 1 / no - 0] 
        1,
        #16 - "Social smoker" bool[yes - 1 / no - 0] 
        1,
        #17 - "Pet 
        8,
        #18 - "Weight 
        50,
        #19 - "Height 
        150,
        #20 - "Body mass index 
        30, 
        #21 - Default 0
        0
        ]

#new instance
Absenteeism_Kmeansmodel = load(open('/content/Kmeansmodel_Absenteeism.pkl', 'rb'))
Absenteeism_Emmodel = load(open('/content/Emmodel_Absenteeism.pkl', 'rb'))
Absenteeism_Normalizer = load(open('/content/Normalizermodel_Absenteeism.pkl', 'rb'))

normalized_input = Absenteeism_Normalizer.transform([input])

data_output_kmeans = predict_kmeans(normalized_input)
data_output_em = predict_em(normalized_input)

data_output_kmeans

"""Now with the Input in the Cluster we can see the field "Absenteeism time over 8 hours", if it's > 0.5 then the Input has high chances of Absenteeism

Ao verificar se uma nova instância tem indicativo de absenteísmo, utilize os dois modelos é uma estratégia denominada hard fail, na qual, se um dos modelos indicar risco de falta (absenteísmo) essa será a inferência do sistema;

Faltou fazer essa parte aqui, nao consegui fazer o EM funcionar direito, se o professor puder me ajudar com isso depois... Tambem nao sei se assumir que a coluna over8 seja maior que 0.5 traz a garantia de que a pessoa terá absenteismo

Quais são as causas de absenteísmo no trabalho conforme essa base de dados?

Aqui eu nao consegui desenvolver um código, mas entendo o df no olho e fazendo alguns testes, percebi que "Social Drinker" e "Social Smoker" são a coluna que tem o maior peso na determinacao de uma pessoa absenteista.
"""